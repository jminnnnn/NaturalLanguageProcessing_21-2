{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "- csv 파일을 읽어서 torchtext를 사용하여 데이터를 신경망에 입력가능한 꼴로 바꾸기\n",
    "(Field, Iterator, train,test, evaluation and prediction)\n",
    "- base line으로 Naive Bayes classification 구현\n",
    "- 한국어 데이터 전처리를 위한 함수를 만들고 이를 torchtext에 통합하기 \n",
    "- 제시된 여러 모델을 사용하여(transformers 제외) 성능을 향상 시키기\n",
    "- training, evaluation 한 것을 test 데이터에 적용하여 성능을 보이기.\n",
    "- predict를 사용하여 제시된 기사들의 분류 결과를 보이기\n",
    "\n",
    "- 참고 사이트\n",
    "    - https://pytorch.org/text/\n",
    "    - http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "    - https://github.com/pytorch/text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내용\n",
    "\n",
    "- 첨부된 BalancedNewsCorpus_train.csv, BalancedNewsCorpus_test.csv는 국어원 뉴스 자료에서 9개 분야의 신문별 균형을 맞춘 자료로, 학습용 9,000개 시험용 1800 자료가 있는 파일이다.\n",
    "- 이 파일을 가지고 https://github.com/bentrevett/pytorch-sentiment-analysis 에 있는 pytorch sentiment analysis의 방법을 따라 한국어 뉴스기사 분류기를 만들어라\n",
    "- 한국어 선처리를 위해 함수를 만들어 이를 torchText에 통합하여 사용. preprocessing은 다양한 방법으로 가능함.\n",
    "- baseline으로 Naive Bayes를 사용하고 Neural Network를 사용하는 모델이 얼마나 더 성능의 향상을 이루는지 보여라..\n",
    "- https://github.com/bentrevett/pytorch-sentiment-analysis 에 제시된 방법 중 가장 성능이 좋은 방법을 사용할 수 있음. **단 이 과제에서는 외부 임베딩과, transformers를 사용하는 방법은 적용하지 말것**\n",
    "- Evaluation, Test 성능을 정리하고, 이렇게 학습한 모델로 제시된 User Input에서 제시된 문장의 출력과 정답을 비교 분석하라.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 Package Import\n",
    "import os\n",
    "from io import StringIO\n",
    "import hanja\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from konlpy.tag import Mecab\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(319)\n",
    "np.random.seed(319)\n",
    "torch.manual_seed(319)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : {7200} valid : {1800} test : {1800}\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "# 한자는 hanja를 통해 번역, 그외 영어나 기호는 삭제\n",
    "\n",
    "train_data_path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_train.csv'\n",
    "test_data_path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_test.csv'\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = hanja.translate(text, 'substitution')\n",
    "    korean_list = re.compile('[ㄱ-ㅎ 가-힣]+').findall(text)\n",
    "    text = ' ' + ' '.join([word for word in korean_list]) + \" \"\n",
    "    return text\n",
    "\n",
    "\n",
    "# Doing the preprocessing\n",
    "train_data = train_df['News'].apply(lambda x: preprocess(x))\n",
    "test_data = test_df['News'].apply(lambda x: preprocess(x))\n",
    "\n",
    "# Extracting Label\n",
    "train_labels = train_df['Topic']\n",
    "test_labels = test_df['Topic']\n",
    "\n",
    "\n",
    "# Download preprocessed data csv\n",
    "temp_train_df = pd.concat([train_data, train_labels], axis=1)\n",
    "temp_train_df, temp_valid_df = train_test_split(temp_train_df, test_size=0.2)\n",
    "\n",
    "temp_test_df = pd.concat([test_data, test_labels], axis=1)\n",
    "path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_'\n",
    "\n",
    "temp_train_data_path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_train_temp.csv'\n",
    "temp_valid_data_path = path + 'valid_temp.csv'\n",
    "temp_test_data_path = path + 'test_temp.csv'\n",
    "\n",
    "temp_train_df.to_csv(temp_train_data_path, index=False)\n",
    "temp_valid_df.to_csv(temp_valid_data_path, index=False)\n",
    "temp_test_df.to_csv(temp_test_data_path, index=False)\n",
    "print('train :', {temp_train_df.shape[0]}, 'valid :', {temp_valid_df.shape[0]}, 'test :', {temp_test_df.shape[0]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloading\n",
    "path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_'\n",
    "temp_train_path = path + 'train_temp.csv'\n",
    "temp_valid_path = path + 'valid_temp.csv'\n",
    "temp_test_path = path + 'test_temp.csv'\n",
    "\n",
    "temp_train_data = pd.read_csv(temp_train_path)\n",
    "temp_valid_data = pd.read_csv(temp_valid_path)\n",
    "temp_test_data = pd.read_csv(temp_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space 단위 tokenizing 함수\n",
    "def preprocess_text_split(text):\n",
    "    return text.split()\n",
    "\n",
    "# space 단위 tokenizing을 이용한 전처리\n",
    "vectorizer = CountVectorizer(analyzer=preprocess_text_split)\n",
    "\n",
    "# Train X & Y 생성\n",
    "train_data_nb = vectorizer.fit_transform(temp_train_data['News'])\n",
    "train_label_nb = temp_train_data['Topic']\n",
    "\n",
    "# Valid X & Y 및 Test X & Y 생성\n",
    "valid_data_nb = vectorizer.transform(temp_valid_data['News'])\n",
    "valid_label_nb = temp_valid_data['Topic']\n",
    "test_data_nb = vectorizer.transform(temp_test_data['News'])\n",
    "test_label_nb = temp_test_data['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Training accuracy = 97.68055555555556\n",
      "  - Validation accuracy = 74.27777777777777\n",
      "  - Test accuracy = 74.27777777777777\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "NB_split = MultinomialNB()\n",
    "NB_split.fit(train_data_nb, train_label_nb)\n",
    "\n",
    "# Results \n",
    "predictions_train = NB_split.predict(train_data_nb)\n",
    "print('  - Training accuracy = {}'.format(\n",
    "        accuracy_score(predictions_train, train_label_nb) * 100)\n",
    "     )\n",
    "predictions_valid = NB_split.predict(valid_data_nb)\n",
    "print('  - Validation accuracy = {}'.format(\n",
    "        accuracy_score(predictions_valid, valid_label_nb) * 100)\n",
    "     )\n",
    "predictions_test = NB_split.predict(test_data_nb)\n",
    "print('  - Test accuracy = {}'.format(\n",
    "        accuracy_score(predictions_test, test_label_nb) * 100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes 결과 요약\n",
    "- 단순히 regex만 처리하여 한글만 남겼을 때의 test set에서의 정확도는 약 74.8%\n",
    "- 따라서 74.8%를 baseline으로 사용할 계획임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 전처리 데이터를 모델에 사용가능하도록 수정한다\n",
    "\n",
    "# 전처리 끝난 file path\n",
    "path = './BalancedNewsCorpusShuffled/BalancedNewsCorpus_'\n",
    "temp_train_data_path = path + 'train_temp.csv'\n",
    "temp_valid_data_path = path + 'valid_temp.csv'\n",
    "temp_test_data_path = path + 'test_temp.csv'\n",
    "\n",
    "tokenizer = Mecab()\n",
    "\n",
    "TEXT = data.Field(sequential = True,\n",
    "                  use_vocab = True,\n",
    "                  tokenize = tokenizer.morphs, # 토크나이저로는 Mecab 사용.\n",
    "                  batch_first=True,\n",
    "                  )\n",
    "\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "        path='./', train=temp_train_data_path, test=temp_test_data_path, format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n",
    "\n",
    "valid_data, _ = TabularDataset.splits(\n",
    "        path='./', train=temp_valid_data_path, test=temp_test_data_path, format='csv',\n",
    "        fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT 집합의 크기: 66337\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print('TEXT 집합의 크기: {0}'.format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 모델 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model structure\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout):        \n",
    "        super().__init__()        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [sent len, batch size]              \n",
    "        embedded = self.embedding(text)                \n",
    "        #embedded = [batch size, sent len, emb dim]        \n",
    "        embedded = embedded.unsqueeze(1)        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]        \n",
    "        #pooled_n = [batch size, n_filters]        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):   \n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0 \n",
    "    \n",
    "    model.train() \n",
    "    \n",
    "    for batch in iterator:      \n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        predictions = model(batch.text)  \n",
    "        \n",
    "        loss = criterion(predictions, batch.label)    \n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)   \n",
    "        \n",
    "        loss.backward()        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()      \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):   \n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()    \n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        \n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)            \n",
    "            loss = criterion(predictions, batch.label)            \n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=len(TEXT.vocab)\n",
    "embedding_dim=300\n",
    "filter_sizes=[2,3,4]\n",
    "output_dim=len(LABEL.vocab)\n",
    "n_filters=120\n",
    "dropout=0.5\n",
    "\n",
    "model=CNN(input_dim,embedding_dim, n_filters, filter_sizes, output_dim, dropout)\n",
    "\n",
    "batch_size=64\n",
    "optimzer=optim.Adam(model.parameters())\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "criterion=criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = batch_size,\n",
    "    sort=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #: 1\n",
      "Train loss is: 2.09\n",
      "Train accuracy is: 0.29\n",
      "val loss is: 1.19\n",
      "val accuracy is: 0.60\n",
      "------------------------------\n",
      "epoch #: 2\n",
      "Train loss is: 1.27\n",
      "Train accuracy is: 0.57\n",
      "val loss is: 0.99\n",
      "val accuracy is: 0.67\n",
      "------------------------------\n",
      "epoch #: 3\n",
      "Train loss is: 1.04\n",
      "Train accuracy is: 0.65\n",
      "val loss is: 0.86\n",
      "val accuracy is: 0.71\n",
      "------------------------------\n",
      "epoch #: 4\n",
      "Train loss is: 0.91\n",
      "Train accuracy is: 0.69\n",
      "val loss is: 0.79\n",
      "val accuracy is: 0.73\n",
      "------------------------------\n",
      "epoch #: 5\n",
      "Train loss is: 0.79\n",
      "Train accuracy is: 0.74\n",
      "val loss is: 0.78\n",
      "val accuracy is: 0.74\n",
      "------------------------------\n",
      "epoch #: 6\n",
      "Train loss is: 0.72\n",
      "Train accuracy is: 0.76\n",
      "val loss is: 0.76\n",
      "val accuracy is: 0.74\n",
      "------------------------------\n",
      "epoch #: 7\n",
      "Train loss is: 0.66\n",
      "Train accuracy is: 0.78\n",
      "val loss is: 0.73\n",
      "val accuracy is: 0.75\n",
      "------------------------------\n",
      "epoch #: 8\n",
      "Train loss is: 0.56\n",
      "Train accuracy is: 0.81\n",
      "val loss is: 0.73\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 9\n",
      "Train loss is: 0.49\n",
      "Train accuracy is: 0.84\n",
      "val loss is: 0.70\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 10\n",
      "Train loss is: 0.46\n",
      "Train accuracy is: 0.84\n",
      "val loss is: 0.70\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 11\n",
      "Train loss is: 0.38\n",
      "Train accuracy is: 0.87\n",
      "val loss is: 0.69\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 12\n",
      "Train loss is: 0.36\n",
      "Train accuracy is: 0.87\n",
      "val loss is: 0.70\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 13\n",
      "Train loss is: 0.29\n",
      "Train accuracy is: 0.90\n",
      "val loss is: 0.69\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 14\n",
      "Train loss is: 0.27\n",
      "Train accuracy is: 0.91\n",
      "val loss is: 0.73\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 15\n",
      "Train loss is: 0.21\n",
      "Train accuracy is: 0.93\n",
      "val loss is: 0.70\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 16\n",
      "Train loss is: 0.20\n",
      "Train accuracy is: 0.94\n",
      "val loss is: 0.73\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 17\n",
      "Train loss is: 0.16\n",
      "Train accuracy is: 0.95\n",
      "val loss is: 0.74\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 18\n",
      "Train loss is: 0.14\n",
      "Train accuracy is: 0.96\n",
      "val loss is: 0.75\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 19\n",
      "Train loss is: 0.11\n",
      "Train accuracy is: 0.97\n",
      "val loss is: 0.74\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 20\n",
      "Train loss is: 0.10\n",
      "Train accuracy is: 0.97\n",
      "val loss is: 0.78\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 21\n",
      "Train loss is: 0.09\n",
      "Train accuracy is: 0.97\n",
      "val loss is: 0.78\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 22\n",
      "Train loss is: 0.07\n",
      "Train accuracy is: 0.98\n",
      "val loss is: 0.80\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 23\n",
      "Train loss is: 0.06\n",
      "Train accuracy is: 0.98\n",
      "val loss is: 0.79\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 24\n",
      "Train loss is: 0.05\n",
      "Train accuracy is: 0.98\n",
      "val loss is: 0.81\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 25\n",
      "Train loss is: 0.05\n",
      "Train accuracy is: 0.98\n",
      "val loss is: 0.81\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 26\n",
      "Train loss is: 0.05\n",
      "Train accuracy is: 0.99\n",
      "val loss is: 0.83\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 27\n",
      "Train loss is: 0.04\n",
      "Train accuracy is: 0.99\n",
      "val loss is: 0.82\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 28\n",
      "Train loss is: 0.04\n",
      "Train accuracy is: 0.99\n",
      "val loss is: 0.89\n",
      "val accuracy is: 0.76\n",
      "------------------------------\n",
      "epoch #: 29\n",
      "Train loss is: 0.03\n",
      "Train accuracy is: 0.99\n",
      "val loss is: 0.90\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n",
      "epoch #: 30\n",
      "Train loss is: 0.03\n",
      "Train accuracy is: 0.99\n",
      "val loss is: 0.89\n",
      "val accuracy is: 0.77\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_epoch=30\n",
    "\n",
    "best_val_loss=float('inf')\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    train_loss, train_acc= train(model,train_iterator,optimzer,criterion)\n",
    "    val_loss, val_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss= val_loss\n",
    "        torch.save(model.state_dict(),'best_cnn_clf.pt')\n",
    "        \n",
    "    print('epoch #: {0}'.format(i+1))\n",
    "    print('Train loss is: {:.2f}'.format(train_loss))\n",
    "    print('Train accuracy is: {:.2f}'.format(train_acc))\n",
    "    print('val loss is: {:.2f}'.format(val_loss))\n",
    "    print('val accuracy is: {:.2f}'.format(val_acc))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.59\n",
      "Test acc : 0.81\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_cnn_clf.pt'))\n",
    "test_loss,test_acc = evaluate(model, test_iterator, criterion)\n",
    "print('Test loss : {:.2f}'.format(test_loss))\n",
    "print('Test acc : {:.2f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network 결과 요약\n",
    "- Naive Bayesian에서 모델을 제외하고 Naive Baysian과 동일한 가정에서 CNN을 사용했을 경우 test set에서의 정확도는 약 79%\n",
    "- 따라서 Neural method 중 하나인 CNN은 baseline인 Naive Baysian보다 4.2%p 높은 정확도를 갖는다고 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래 문장의 정답은 8-4-1-3-5-6-0-2-7\n",
    "## 연예/문화, 정치/경제/사회/생활 등 명확히 구별되기 어려운 범주들이 있음...\n",
    "\n",
    "\n",
    "input_data= pd.DataFrame([\"여러 차례 선거를 치르며 조직적인 지지모임과 온라인 팬덤을 보유한 이 지사에 비해 부족하다는 것이다. 윤석열 캠프에선 오차범위를 다투는 여론조사 지지율과는 별개로, ‘조직’에 있어선 아직도 채워야 할 부분이 많다는 이야기가 나온다. 윤석열 캠프 관계자는 “사람만 많이 모은다고 좋을 게 없다는 지적을 듣기도 하지만, 인구 1300만명의 지자체장인 이재명 지사에 비하면 많은 게 아닌 상황”이라고 말했다.\", \n",
    "\"여자친구가 이별을 통보하고 새 남자친구를 사귀자 지속적으로 찾아가 협박과 폭행을 가한 30대 남성이 실형을 선고 받았다. 창원지법 형사4단독 안좌진 부장판사는 상해, 주거침입, 폭행 등 혐의로 재판에 넘겨진 A(39)씨에게 징역 1년3개월을 선고했다고 10일 밝혔다.A씨는 지난해 4월부터 올해 2월까지 10개월 가량 사귄 B씨(30)가 이별을 통보하자 지난 3월 6일 B씨 집을 찾아가 욕설을 퍼붓고 B씨를 폭행한 혐의를 받고 있다.\",\n",
    "\"동탄신도시의 성공은 명실상부한 한국 1위의 기업 삼성전자를 빼놓고는 설명할 수 없다. 삼성전자는 수출의 20%를 담당하는 한국 경제의 심장이다. 삼성전자의 연구소와 공장은 세계 최고 수준의 연구인력과 협력업체를 끌어당기는 블랙홀이다.동탄신도시 인근에 삼성전자 기흥캠퍼스가 있고 화성캠퍼스가 신도시에 자리 잡고 있다. 삼성 화성캠퍼스에서는 메모리와 파운드리 반도체의 설계 및 생산이 이뤄지고 있다.\",\n",
    "\"샤워나 목욕 중에는 물, 샤워타올, 수건 등 균이 닿을 여지가 많다. 샤워를 하는 화장실에는 보통 변기도 함께 있어 배변 활동으로 나온 균이 공기 중을 돌아다니고 있다. 습기가 높아 곰팡이가 생기기도 좋은 환경이다. 화장실에 걸린 샤워타올과 수건이 제대로 건조되지 않은 채 화장실에 내내 있었다면 균이 있을 가능성이 크다. 이 균이 예방 접종 하면서 생긴 손상 부위에 닿으면 드물지만 침입해 감염증을 유발할 수 있다.\",\n",
    "\"식전주의 시간이다. 밥을 먹기 전에 마시는 술. 안주와 함께 먹지 않는 술. 술만으로 온전한 술. 이게 식전주다. 3시와 5시 사이는 식전주의 시간이기도 한 것이다. 이 시간에 마시는 식전주를 나는 꽤나 좋아한다. 술은 다 각각의 매력이 있고, 슬플 때도 기쁠 때도 지루할 때도 피곤할 때도 좋지만, 식전주의 시간에 마시는 식전주도 좋다. 주로 맥주이지만 가끔은 아페리티프(Aperitif·식전주)를 마신다.\",\n",
    "\"시리아전을 마친 뒤 9일 이란으로 출국한 한국 대표팀은 한국 시간 기준 10일 오전 1시경 테헤란 공항에 도착해 숙소인 파르시안 아자디 호텔로 이동했다. 이후 코로나19 PCR 검사를 진행했고, 결과가 나올 때까지 각자 방에서 격리한 채 대기할 예정이다. 한국은 역대 이란 원정에서 한차례도 승리하지 못한 채 2무 5패를 기록 중이다.  선수들이 좋은 컨디션을 유지할 수 있도록 전세기를 마련해 이란으로 향했다.\",\n",
    "\"애플의 아이폰13 시리즈가 지난 8일 국내 판매를 시작했다. 애플이 지난달 14일(현지시각) 신제품을 공개한 후 3주 만이다. 애플은 아이폰13의 두뇌에 해당하는 프로세서와 카메라 성능을 크게 개선했다고 밝혔다. 팀 쿡 애플 최고경영자(CEO)는 “역사상 최고의 아이폰이다”라고 했다. 하지만 전작인 아이폰12와 비교해 큰 차이를 느낄 수 없다는 부정적인 평가도 많다.\",\n",
    "\"극단 마실은 문화체육관광부와 지역문화진흥원 지원으로 '심청전-할머니의 비밀레시피' 온라인 만남 행사를 진행했다고 10일 밝혔다. 행사는 할머니만의 레시피로 함께 음식을 만들며 할머니의 이야기를 공유하고, 할머니를 주인공으로 한 짤막한 연극을 펼치는 순서로 진행됐다. 극단은 지역 내 관음사 연기 설화가 심청전과 연관 있는 점을 토대로 심청의 일생과 닮은 곡성 할머니들의 이야기를 2018년도부터 수집해 연극을 만들었다.\",\n",
    "\"‘놀면 뭐하니?+’에서는 유재석, 정준하, 하하, 신봉선, 미주의 깜짝 ‘꼬치꼬치 기자간담회’와 MBC 보도국 열혈 신입기자로 변신한 ‘뉴스데스크’ 특집이 시작됐다. ‘꼬치꼬치 기자간담회’에서는 정준하가 ‘스포츠 꼬치꼬치’ 기자로 변신, 시청자의 궁금증을 풀어주는 마성의 돌직구 질문을 던졌고, ‘놀면 뭐하니?+’ 멤버들은 솔직한 마음이 담긴 답변으로 큰 웃음과 훈훈함을 동시에 선사했다.\"\n",
    "])\n",
    "input_label = pd.DataFrame([\"정치\", \"사회\", \"경제\", \"미용/건강\", \"생활\", \"스포츠\", \"IT/과학\", \"문화\", \"연예\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_length=5):\n",
    "    model.eval()\n",
    "    text_tokenized=tokenizer.morphs(sentence)\n",
    "    if len(text_tokenized) < min_length:\n",
    "        text_tokenized += ['<pad>'] * (min_length - len(text_tokenized))\n",
    "    padded_text_tokenized = [TEXT.vocab.stoi[t] for t in text_tokenized]\n",
    "    tensor = torch.LongTensor(padded_text_tokenized).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = model(tensor).argmax(1)\n",
    "    label_index = prediction.item()\n",
    "    label_string = list(LABEL.vocab.stoi)[label_index]\n",
    "    return label_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results\n",
      "Prediction results: ['정치' '사회' 'IT/과학' '미용/건강' '미용/건강' '스포츠' 'IT/과학' '문화' '연예']\n",
      "Accuracy: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes for comaprison\n",
    "NB_pred=NB_split.predict(vectorizer.transform(input_data[0]))\n",
    "print('Naive Bayes Results')\n",
    "print('Prediction results: {0}'.format(NB_pred))\n",
    "print('Accuracy: {0}'.format(accuracy_score(NB_pred, input_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Results\n",
      "Prediction results: ['사회', '사회', '경제', '미용/건강', '생활', '스포츠', 'IT/과학', '문화', '연예']\n",
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Neural Network Model\n",
    "CNN_pred=[]\n",
    "for sentence in input_data[0]:\n",
    "    pred=predict_news(model, sentence)\n",
    "    CNN_pred.append(pred)\n",
    "print('CNN Results')\n",
    "print('Prediction results: {0}'.format(CNN_pred))\n",
    "print('Accuracy: {0}'.format(accuracy_score(CNN_pred, input_label)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. User Input 테스트에서 정의한 Naive Bayes는 7개를, CNN은 실험마다 다르게 5~8개의 label을 옳게 예측하였다.\n",
    "2. 그런데 Naive Bayes는 원래 학습 결과 정확도가 75%정도 나왔고, CNN은 80%가량 나왔었다.\n",
    "3. 이로부터 알 수 있는 것은 새로운 데이터에 대해 Naive Bayes는 Robustness가 확인된 반면, CNN은 그렇지 못하였다는 것이다.\n",
    "3. 따라서 본 실험에서 내린 결론은 CNN 모델이 상황에 따라서 과적합이 될 수도 있기 때문에 정규화가 더 필요하거나 모델 자체의 개선이 필요하다는 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
